{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "name": "Copia de Carga de datos a PubSub.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiQrhYJ3PPfa"
      },
      "source": [
        "# Carga de datos a PubSub\n",
        "\n",
        "Este notebook se utilizará como una máquina que está cargando datos de forma continua a PubSub.\n",
        "\n",
        "Para conseguir esos datos vamos a coger los datos que se han generado al inicio del curso (datos a nivel día, no datos históricos) y los traemos al directorio de colab:\n",
        "\n",
        "```\n",
        "            TXT_Simulación_TICKETS_YYYY-MM-DD.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdNUQYcvPx_j"
      },
      "source": [
        "Como en otras ocasiones, primero debemos activar Google Drive, donde guardaremos de forma segura nuestros credenciales que nos permitirán autentificarnos. Para ello, efectuamos y seguimos las instrucciones que se nos indiquen en el siguiente bloque:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV3TnzY0PxKj"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE2iaBtjP-bB"
      },
      "source": [
        "A continuación vamos a coger las credenciales que hemos descargado y vamos a pegarlo en la misma carpeta en la que se encuentra este cuaderno:\r\n",
        "\r\n",
        "```\r\n",
        "'drive/\r\n",
        "    My Drive/ \r\n",
        "          credentials.json                               \r\n",
        "```\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4o6pht3Qxnf"
      },
      "source": [
        "Para cerrar la puesta apunto del entorno de trabajo, activamos los credenciales e instalamos librerias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lVCICVWQwG-"
      },
      "source": [
        "import os\r\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/credentials.json' \r\n",
        "!echo $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgp4BZHfRDcV"
      },
      "source": [
        "!pip install google-cloud-pubsub==0.42.1\r\n",
        "!pip install google-api-core==1.13.0\r\n",
        "!pip install APScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv4TUb2UQYJj"
      },
      "source": [
        "Empecemos cargando los datos\r\n",
        "\r\n",
        " >- **Nota**: Los datos a introducir tienen que ser del día actual para que el algoritmo funcione. Recordar que esos datos los obtenemos en el paso\r\n",
        " `0. Pasos previos` y nos los descargamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T13:34:36.700154Z",
          "start_time": "2019-11-27T13:34:36.691156Z"
        },
        "id": "g7tmEV04PPfq"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "\n",
        "# TODO: Copia el nombre del archivo copiado en esta carpeta\n",
        "nombre_archivo = '___________________'\n",
        "\n",
        "df = pd.read_csv(nombre_archivo, parse_dates=['ticketDate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QntVq-iPPfw"
      },
      "source": [
        "Ahora, para lanzar nuestros datos a PubSub, tendremos que volver a especificar el tema y el proyecto que hemos creado en Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T13:34:37.659925Z",
          "start_time": "2019-11-27T13:34:37.651945Z"
        },
        "id": "Fp7pGQ-_PPfx"
      },
      "source": [
        "from google.cloud import pubsub_v1\n",
        "\n",
        "# TODO especificar nuestro 'project_id' y 'topic_name'\n",
        "project_id = '_____________'\n",
        "topic_name = '_____________'\n",
        "\n",
        "# Configure the batch to publish as soon as there is one kilobyte\n",
        "# of data or one second has passed.\n",
        "batch_settings = pubsub_v1.types.BatchSettings(\n",
        "    max_bytes=1024,  # One kilobyte\n",
        "    max_latency=1,   # One second\n",
        ")\n",
        "publisher = pubsub_v1.PublisherClient(batch_settings)\n",
        "topic_path = publisher.topic_path(project_id, topic_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFEInehTPPfz"
      },
      "source": [
        "Una vez que hemos especificado los datos del día, las credenciales y los ID correspondientes, toca subir esos datos. Para ese cometido, vamos a hacerlo en 2 partes:\n",
        "\n",
        " - Para empezar vamos a cargar los datos hasta este instante (hasta el minuto actual en el que ejecutamos el código)\n",
        " - Una vez hemos cargado los datos iniciales, vamos a ir subiendo los datos minuto a minuto (simulando el tiempo real)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-UkyN_tPPf0"
      },
      "source": [
        "Vamos a cargar todos los tickets hasta el minuto actual:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T13:34:41.290506Z",
          "start_time": "2019-11-27T13:34:41.282498Z"
        },
        "id": "CAtJBH3LPPf1"
      },
      "source": [
        "def first_load():\n",
        "    now = datetime.now()\n",
        "    now -= timedelta(seconds=now.second)\n",
        "    now -= timedelta(microseconds=now.microsecond)\n",
        "    \n",
        "    df_now = df[df['ticketDate'] <= now]\n",
        "    for index, row in df_now.iterrows():\n",
        "        json_values = {}\n",
        "        json_values['amount'] = row['amount']\n",
        "        json_values['ticketDate'] = row['ticketDate'].strftime('%Y-%m-%d %H:%M:%S')\n",
        "        \n",
        "        # Convertir diccionario en JSON\n",
        "        json_values = json.dumps(json_values)\n",
        "        \n",
        "        # Codificar String\n",
        "        json_values = json_values.encode('utf-8')\n",
        "        future = publisher.publish(topic_path, data=json_values)\n",
        "        \n",
        "    print('Mensajes Publicados')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rig7jbpkPPf2"
      },
      "source": [
        "para después subirlos minuto a minuto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T13:35:21.081070Z",
          "start_time": "2019-11-27T13:35:21.074061Z"
        },
        "id": "TSbI5umfPPf3"
      },
      "source": [
        "def run():\n",
        "    now = datetime.now()\n",
        "    now -= timedelta(seconds=now.second)\n",
        "    now -= timedelta(microseconds=now.microsecond)\n",
        "    \n",
        "    df_now = df[df['ticketDate'] == now]\n",
        "    for index, row in df_now.iterrows():\n",
        "        json_values = {}\n",
        "        json_values['amount'] = row['amount']\n",
        "        json_values['ticketDate'] = row['ticketDate'].strftime('%Y-%m-%d %H:%M:%S')\n",
        "        \n",
        "        # Convertir diccionario en JSON\n",
        "        json_values = json.dumps(json_values)\n",
        "        \n",
        "        # Codificar String\n",
        "        json_values = json_values.encode('utf-8')\n",
        "        future = publisher.publish(topic_path, data=json_values)\n",
        "        \n",
        "    print('Mensajes Publicados')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEV0KcYyPPf3"
      },
      "source": [
        "Para generar un bucle que se repita cada minuto, vamos a utilizar el módulo `APScheduler` de Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-27T13:35:22.191295Z",
          "start_time": "2019-11-27T13:35:22.186308Z"
        },
        "id": "9i66S_mHPPf4"
      },
      "source": [
        "from apscheduler.schedulers.blocking import BlockingScheduler\n",
        "\n",
        "sched = BlockingScheduler()\n",
        "sched.add_job(run, 'interval', minutes=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNntyM7fPPf5"
      },
      "source": [
        "Ejecutemos...\n",
        "\n",
        " >- **Nota**: el siguiente bloque va a hacer que Python se meta en un bucle infinito, por lo que si se quiere parar tendremos que darle al botón de `Stop` o reiniciar el `Kernel`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-11-27T13:35:22.760Z"
        },
        "scrolled": true,
        "id": "VER9-1vEPPf6"
      },
      "source": [
        "first_load()\n",
        "sched.start()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}