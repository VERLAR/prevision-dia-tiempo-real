{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando el modelo de regresión\n",
    "\n",
    "En este apartado cargaremos los datos históricos y crearemos un modelo de regresión para hacer los cálculos de predicción. Para este ejemplo, utilizaremos el modelo SVR (`Support Vector Regression` del módulo de [scikit-learn](https://scikit-learn.org/stable/index.html) de [Python](https://www.python.org/): [sklearn.svm.SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)), pero se podrían utilizar otros modelos de regresión para comparar los resultados.\n",
    "\n",
    "Los pasos que se seguirán en este *notebook* son los siguientes:\n",
    "\n",
    " 1. [Carga de datos históricos](#Carga-de-datos-históricos)\n",
    " 2. [Preparación de los datos](#Preparación-de-los-datos)\n",
    " 3. [Normalización](#Normalización)\n",
    " 4. [Añadiendo información a los datos de entrada](#Añadiendo-información-a-los-datos-de-entrada)\n",
    " 5. [Training/Test/Validation Set](#Training/Test/Validation-Set)\n",
    " 6. [Creando el modelo](#Creando-el-modelo)\n",
    " 7. [Visualizando los resultados](#Visualizando-los-resultados)\n",
    "\n",
    "## Carga de datos históricos\n",
    "\n",
    "Vamos a empezar cargando los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:11.253319Z",
     "start_time": "2019-11-18T08:44:02.604299Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Datos/Datos2018.txt', parse_dates=['Fecha'])\n",
    "\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestros `dataframe` de momento sólo contiene 2 columnas:\n",
    "\n",
    " - `Fecha`: día y hora de la emisión del ticket (formato `%Y-%m-%d %H:%M:%S`)\n",
    " - `Importe`: importe del ticket en €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:11.275028Z",
     "start_time": "2019-11-18T08:44:11.255081Z"
    }
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y el tipo de dato que contiene cada columna:\n",
    " - `Fecha`: tipo de dato `datetime`\n",
    " - `Importe`: tipo de dato `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:11.416597Z",
     "start_time": "2019-11-18T08:44:11.277023Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "\n",
    "Como se ha indicado al inicio, el objetivo es crear un modelo de **regresión**, por lo que tenemos que preparar los datos de forma que tengamos unos datos de entrada $X$ y otros de salida $Y$.\n",
    "\n",
    "Para ello, vamos a intentar transformar nuestro `dataframe` para que tenga un formato similar a la siguiente tabla (en donde las ventas se van acumulando cada 15 minutos hasta llegar a las ventas totales del día: `22:00`):\n",
    "\n",
    "| Dia | 09:00 | 09:15 | 09:30 | ... | 21:30 | 21:45 | 22:00 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 2019-09-26 | 0 | 20 000 | 51 000 | ... | 5 000 000 | 5 000 100 | 5 000 150 |\n",
    "| 2019-09-27 | 0 | 20 200 | 51 400 | ... | 5 500 000 | 5 500 100 | 5 500 150 |\n",
    "| 2019-09-28 | 0 | 23 000 | 53 000 | ... | 6 000 000 | 6 000 100 | 6 000 150 |\n",
    "\n",
    "De esta manera, tendríamos los datos de entrada $X$ (en el que se introducirán más variables):\n",
    "\n",
    "| 09:00 | 09:15 | 09:30 | ... | 21:30 | 21:45 |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 20 000 | 51 000 | ... | 5 000 000 | 5 000 100 |\n",
    "| 0 | 20 200 | 51 400 | ... | 5 500 000 | 5 500 100 |\n",
    "| 0 | 23 000 | 53 000 | ... | 6 000 000 | 6 000 100 |\n",
    "\n",
    "Y los datos de salida $Y$:\n",
    "\n",
    "| 22:00 |\n",
    "| --- |\n",
    "| 5 000 150 |\n",
    "| 5 500 150 |\n",
    "| 6 000 150 |\n",
    "\n",
    "Para preparar esa tabla, vamos a empezar agregando las ventas en intervalos de 15 minutos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:11.471563Z",
     "start_time": "2019-11-18T08:44:11.418563Z"
    }
   },
   "outputs": [],
   "source": [
    "df.index = df.pop('Fecha')\n",
    "df = df.resample('15T').sum()\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuaremos desglosando la `Fecha` en 2 nuevas columnas:\n",
    " - `Dia`\n",
    " - `Hora`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:11.989191Z",
     "start_time": "2019-11-18T08:44:11.474525Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Dia'] = df.index.map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "df['Hora'] = df.index.map(lambda x: x.strftime('%H:%M'))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya estamos listos para formatear nuestro `dataframe`, para ello utilizaremos la función [crosstab](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) del módulo de [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.056001Z",
     "start_time": "2019-11-18T08:44:11.991145Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.crosstab(index=df['Dia'],\n",
    "                 columns=[df['Hora']],\n",
    "                 values=df.Importe,\n",
    "                 aggfunc=sum).fillna(0).reset_index()\n",
    "\n",
    "df.set_index('Dia', inplace=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar con esta parte, vamos hacer la suma acumulada de cada fila:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.100861Z",
     "start_time": "2019-11-18T08:44:12.058966Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.cumsum(axis=1)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "\n",
    "Para la normalización de los datos vamos a dividir todos los campos por el máximo valor de la tabla. De esa manera, todos nuestros valores oscilarán entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.183691Z",
     "start_time": "2019-11-18T08:44:12.103845Z"
    }
   },
   "outputs": [],
   "source": [
    "max_value = df['23:45'].max()\n",
    "df /= max_value\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadiendo información a los datos de entrada\n",
    "\n",
    "Una vez que hemos preparado los datos para poder aplicar un modelo de regresión, vamos a añadir información adicional a los datos para intentar crear un modelo más afinado. En este caso vamos a añadir información de calendario:\n",
    "\n",
    " - Día de la semana\n",
    " - Días festivos\n",
    " \n",
    "Esas nuevas variables van a ser variables **categóricas** por lo que crearemos [variables *dummy*](https://medium.com/hugo-ferreiras-blog/dealing-with-categorical-features-in-machine-learning-1bb70f07262d) para introducirlo en el modelo.\n",
    "\n",
    "### Días de la semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.216573Z",
     "start_time": "2019-11-18T08:44:12.185656Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Dia'] = pd.to_datetime(df['Dia'])\n",
    "weekdays = [\n",
    "    [0, 'Lunes'],\n",
    "    [1, 'Martes'],\n",
    "    [2, 'Miercoles'],\n",
    "    [3, 'Jueves'],\n",
    "    [4, 'Viernes'],\n",
    "    [5, 'Sabado'],\n",
    "    [6, 'Domingo']\n",
    "]\n",
    "for weekday, weekday_name in weekdays:\n",
    "    df[weekday_name] = df['Dia'].map(lambda x: x.weekday() == weekday)\n",
    "    \n",
    "df[['Dia', 'Lunes', 'Martes', 'Miercoles',\n",
    "    'Jueves', 'Viernes', 'Sabado', 'Domingo']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Días Festivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.260100Z",
     "start_time": "2019-11-18T08:44:12.218568Z"
    }
   },
   "outputs": [],
   "source": [
    "calendario = ['2019-01-01']\n",
    "\n",
    "df['Festivo'] = df['Dia'].isin(calendario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test/Validation Set\n",
    "\n",
    "Por último, antes de crear el modelo vamos a dividir los datos en 3 bloques:\n",
    "\n",
    " - **Training Set**: 80% de los datos\n",
    " - **Test Set**: 10% de los datos\n",
    " - **Validation Set**: 10% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.312787Z",
     "start_time": "2019-11-18T08:44:12.262064Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_test_set():\n",
    "    # Training Set (80%)\n",
    "    train_data = df.sample(frac=0.8, random_state=0)\n",
    "    test_validation_data = df.drop(train_data.index)\n",
    "\n",
    "    # Test/Validatin Set (10%/10%)\n",
    "    test_data = test_validation_data.sample(frac=0.5, random_state=0)\n",
    "    validation_data = test_validation_data.drop(test_data.index)\n",
    "\n",
    "    # Definir la variable 'Y'\n",
    "    train_y = train_data.pop('23:45')\n",
    "    test_y = test_data.pop('23:45')\n",
    "    validation_y = validation_data.pop('23:45')\n",
    "\n",
    "    # Eliminamos la columna 'Dia'\n",
    "    train_data.drop(['Dia'], axis=1, inplace=True)\n",
    "    test_data.drop(['Dia'], axis=1, inplace=True)\n",
    "    validation_data.drop(['Dia'], axis=1, inplace=True)\n",
    "    \n",
    "    return [train_data, test_data, validation_data, train_y, test_y, validation_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando el modelo\n",
    "\n",
    "Como se ha indicado en la introducción, en este ejemplo se va a utilizar el modelo [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) para la regresión y se va a elegir el `kernel` `rbf`.\n",
    "\n",
    "No es objeto de este *notebook* explicar los detalles de este modelo, pero el lector que esté interesado en profundizar en este modelo puede ver con más detalle los algoritmos que se utilizan para hacer los cálculos en la documentación oficial de [scikit-learn](https://scikit-learn.org/stable/modules/svm.html#svm-regression).\n",
    "\n",
    "En `SVR` hay básicamente 2 parámetros que se utilizan para ajustar el modelo:\n",
    "\n",
    " - `C`\n",
    " - `Epsilon`\n",
    " \n",
    "a los que vamos a darle diferentes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.935853Z",
     "start_time": "2019-11-18T08:44:12.317743Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def crear_modelo():\n",
    "    error = -1\n",
    "\n",
    "    for C in [0.1, 1, 100, 1000]:\n",
    "        for epsilon in [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]:\n",
    "            # Creamos el modelo con los parámetros seleccionados\n",
    "            svr_rbf = SVR(kernel='rbf', C=C, gamma='auto', epsilon=epsilon)\n",
    "\n",
    "            # Ajustamos el modelo a nuestros datos\n",
    "            model = svr_rbf.fit(train_data, train_y)\n",
    "\n",
    "            # Medir la calidad del modelo con el Test Set\n",
    "            error_now = (model.predict(test_data) - test_y).std()\n",
    "\n",
    "            # Guardar los parámetros si se ha mejorado el error\n",
    "            if (error_now < error) or (error == -1):\n",
    "                error = error_now\n",
    "                C_good = C\n",
    "                epsilon_good = epsilon\n",
    "                \n",
    "    return SVR(kernel='rbf', C=C_good, gamma='auto', epsilon=epsilon_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos crear diferentes modelos para cada hora, a la hora de crear el modelo tendremos que modificar las variables de entrada $X$, eliminando las columnas que no se van a tener en cuenta para el modelo. Para ese fin vamos a definir la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:12.942807Z",
     "start_time": "2019-11-18T08:44:12.937823Z"
    }
   },
   "outputs": [],
   "source": [
    "def eliminar_columnas(hour_now):\n",
    "    \"\"\"Eliminar las columnas que no se van a utilizar para el cálculo de las previsiones\"\"\"\n",
    "\n",
    "    cols_drop = df.columns[(df.columns > hour_now) & (df.columns < '23:45')]\n",
    "    for col in cols_drop:\n",
    "        df.pop(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También vamos a necesitar otra función para guardar los modelos utilizando el módulo `joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:13.023059Z",
     "start_time": "2019-11-18T08:44:12.944800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "\n",
    "def guardar_modelo_svr(name):\n",
    "    \"\"\"Guardar los resultados del modelo\"\"\"\n",
    "\n",
    "    folder = 'modelos/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    filename = 'modelo_' + name + '.sav'\n",
    "    joblib.dump(model, folder + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:13.112072Z",
     "start_time": "2019-11-18T08:44:13.025057Z"
    }
   },
   "outputs": [],
   "source": [
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pongamos en marcha los cálculos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:21.830206Z",
     "start_time": "2019-11-18T08:44:13.116021Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for hour in range(10, 22):\n",
    "    print('\\nCreando modelo para las ' + str(hour) + '...')\n",
    "    df = df_orig.copy()\n",
    "    eliminar_columnas(str(hour) + ':00')\n",
    "    train_data, test_data, validation_data, train_y, test_y, validation_y = training_test_set()\n",
    "    model = crear_modelo()\n",
    "    model.fit(train_data, train_y)\n",
    "    guardar_modelo_svr(str(hour) + '00')\n",
    "    print('Modelo guardado!')\n",
    "    print('Error de validación: ' + str((model.predict(validation_data) - validation_y).std()))\n",
    "\n",
    "# Guardamos también el valor máximo 'max_value'\n",
    "file = open('modelos/max_value.txt', 'w')\n",
    "file.write(str(round(max_value, 2)))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todo ha ido bien, habremos creado los siguientes archivos en nuestro ordenador (puede variar ligeramente la imagen), es decir, habremos guardado con éxito los modelos.\n",
    "\n",
    "```\n",
    "1. Creando el modelo predictivo/\n",
    "    Datos\n",
    "    Modelo/\n",
    "        .ipynb_checkpoints\n",
    "        modelos/\n",
    "            max_value.txt\n",
    "            modelo_1000.sav\n",
    "            modelo_1100.sav\n",
    "            modelo_1200.sav\n",
    "            modelo_1300.sav\n",
    "            modelo_1400.sav\n",
    "            modelo_1500.sav\n",
    "            modelo_1600.sav\n",
    "            modelo_1700.sav\n",
    "            modelo_1800.sav\n",
    "            modelo_1900.sav\n",
    "            modelo_2000.sav\n",
    "            modelo_2100.sav\n",
    "            modelo_2200.sav\n",
    "            modelo_2300.sav\n",
    "    Modelo.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando los resultados\n",
    "\n",
    "Cargamos las librerias de [Plotly](https://plot.ly/python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:22.222645Z",
     "start_time": "2019-11-18T08:44:21.832201Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos los días que queremos mostrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:22.749490Z",
     "start_time": "2019-11-18T08:44:22.224640Z"
    }
   },
   "outputs": [],
   "source": [
    "dias = df_orig.loc[df_orig.index.isin(validation_y.index), 'Dia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el modelo que queremos analizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:44:22.823046Z",
     "start_time": "2019-11-18T08:44:22.751485Z"
    }
   },
   "outputs": [],
   "source": [
    "hour = 14\n",
    "\n",
    "# Cargamos el modelo\n",
    "loaded_model = joblib.load('modelos/modelo_{}00.sav'.format(str(hour)))\n",
    "\n",
    "# Creamos los datos de validación\n",
    "df = df_orig.copy()\n",
    "eliminar_columnas(str(hour) + ':00')\n",
    "train_data, test_data, validation_data, train_y, test_y, validation_y = training_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:45:32.176577Z",
     "start_time": "2019-11-18T08:45:31.950203Z"
    }
   },
   "outputs": [],
   "source": [
    "iplot({\n",
    "    'data': [go.Scatter(\n",
    "                x=dias,\n",
    "                y=validation_y * max_value,\n",
    "                name='Real'\n",
    "            ),go.Scatter(\n",
    "                x=dias,\n",
    "                y=loaded_model.predict(validation_data) * max_value,\n",
    "                name='Predicción'\n",
    "    )],\n",
    "    'layout': go.Layout(\n",
    "                yaxis={\n",
    "                    'title': 'Ventas €'\n",
    "                }\n",
    "    )\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
